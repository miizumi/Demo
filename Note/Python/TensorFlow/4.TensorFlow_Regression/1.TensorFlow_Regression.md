# TensorFlow  回歸


_參照code：1.TensorFlow_Regression.py_


前面使用的都是分類法，這裡要用回歸法來預測數字答案。

預測數字型答案的結果未必漂亮，還是建議改成分類型，比如：預測房屋價格 → 低、中、高價格。

做回歸分析的模型，需要記得幾個重點。

1. 輸出只有一個：因為只有一個答案輸出。
2. 最後隱藏層的激勵函式通常使用tf.nn.relu。
3. 編譯：指標使用的參數不同。
4. 訓練次數： 訓練次數要比分類更多。


備註：主要看loss率判斷好壞，當預測結果不理想或無法上升，應該著重於Data Cleaning。

<br/>

## 資料準備

random_state =隨機種子

簡而言之，在隨機數中使用相同的隨機種子，會得到相同的結果。

```python
X = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])
Y = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])
#資料切割
X_Train,X_Test,Y_Train,Y_Test=train_test_split(X,Y,test_size=0.1,random_state=42)   
```

<br/>

## 建立模型

注意輸出只能有一個。

```python
model=tf.keras.models.Sequential([
       tf.keras.layers.Dense(units=1,input_dim=1)
])
```

## 編譯

要挑選適合迴歸的編譯。

```python
model.compile(loss='mse',optimizer='sgd',metrics=['accuracy']) #適合用回歸
```

## 手算答案

先取得權重 (權重，閾值)，再做運算。

運算= 特徵值 * 權重 + 閾值

```python
weights , biases =model.layers[0].get_weights() 

#產生0~1之間，連續100個數字。
x2 = np.linspace(0,1,100)   
y2 = (x2 * weights[0] + biases[0])
```

## 繪製圖表

```python
plt.scatter(X,Y)            #X,Y散佈圖
plt.scatter(X_Test,Y_Test)  #測試集散佈圖
plt.plot(X_Test,Y_Predict)  #預測線圖
plt.plot(x2,y2,'-r',label='weights')
plt.legend()
plt.show()
```
